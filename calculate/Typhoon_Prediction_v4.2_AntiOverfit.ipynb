{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üåÄ Typhoon Prediction Model v4.2 - Anti-Overfitting Edition\n",
        "\n",
        "## Major Changes from v4.1:\n",
        "\n",
        "### Problems Identified in v4.1:\n",
        "- **Japan Sea**: Train R¬≤=1.0, Test R¬≤=-2.36 ‚Üí **Severe Overfitting**\n",
        "- **South China Sea & Yellow Sea**: Variance Ratio ‚âà 0 ‚Üí **Still Flat**\n",
        "- **All regions**: Negative Test R¬≤ ‚Üí **Worse than mean prediction**\n",
        "- **SVR** keeps winning but performs poorly\n",
        "\n",
        "### v4.2 Fixes:\n",
        "1. **Remove SVR** - Not suitable for this small, noisy dataset\n",
        "2. **Stronger regularization** - Prevent overfitting\n",
        "3. **Simpler models** - Linear models + KNN only\n",
        "4. **Fewer features** - Reduce to 2-3 most important\n",
        "5. **Add baseline comparison** - Compare against simple mean prediction\n",
        "6. **Ensemble averaging** - Combine multiple models\n",
        "7. **Constraint: Only use models with Train R¬≤ < 0.5** - Prevent overfitting\n",
        "\n",
        "---\n",
        "‚è±Ô∏è **Estimated Runtime**: 3-5 minutes"
      ],
      "metadata": {
        "id": "header_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Environment Setup"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from itertools import product\n",
        "\n",
        "# Simpler models only - NO SVR\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet, BayesianRidge, LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import LeaveOneOut, cross_val_predict\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# For correlation analysis\n",
        "from scipy import stats\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")\n",
        "print(\"\\nüîë Key Changes in v4.2:\")\n",
        "print(\"   ‚Ä¢ REMOVED SVR (causes overfitting/flat predictions)\")\n",
        "print(\"   ‚Ä¢ Added LinearRegression as baseline\")\n",
        "print(\"   ‚Ä¢ Stronger regularization\")\n",
        "print(\"   ‚Ä¢ Maximum 2-3 features per region\")\n",
        "print(\"   ‚Ä¢ Anti-overfitting constraint (Train R¬≤ < 0.5)\")"
      ],
      "metadata": {
        "id": "setup_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ Upload Data Files"
      ],
      "metadata": {
        "id": "upload_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "print(\"Please upload: typhoon_count.csv and MEI/PDO/IOD/QBO NC files\")\n",
        "uploaded = files.upload()\n",
        "print(f\"\\n‚úÖ Uploaded {len(uploaded)} files\")"
      ],
      "metadata": {
        "id": "upload_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Check NC Files"
      ],
      "metadata": {
        "id": "check_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for f in [f for f in os.listdir('.') if f.endswith('.nc')]:\n",
        "    ds = xr.open_dataset(f)\n",
        "    print(f\"{f}: variables={list(ds.data_vars)}\")\n",
        "    ds.close()"
      ],
      "metadata": {
        "id": "check_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ Configuration v4.2\n",
        "\n",
        "### Critical Changes:\n",
        "- **NO SVR** - Removed entirely\n",
        "- **MAX_FEATURES = 2** - Reduced from 4\n",
        "- **Strong regularization** - Higher alpha values\n",
        "- **Anti-overfitting check** - Reject models with Train R¬≤ > 0.5"
      ],
      "metadata": {
        "id": "config_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    # Data files\n",
        "    TYPHOON_DATA_PATH = 'typhoon_count.csv'\n",
        "    MEI_NC_PATH = 'mei_v2.nc'\n",
        "    PDO_NC_PATH = 'pdo_ersst_v5.nc'\n",
        "    IOD_NC_PATH = 'iod_ersst_v5.nc'\n",
        "    QBO_NC_PATH = 'qbo.nc'\n",
        "\n",
        "    # Variable names\n",
        "    MEI_VAR_NAME = 'mei'\n",
        "    PDO_VAR_NAME = 'pdo'\n",
        "    IOD_VAR_NAME = 'iod'\n",
        "    QBO_VAR_NAME = 'value'\n",
        "    TIME_VAR_NAME = 'time'\n",
        "\n",
        "    # Time range\n",
        "    START_YEAR = 1980\n",
        "    END_YEAR = 2024\n",
        "    PREDICT_YEAR = 2025\n",
        "    TEST_SPLIT_YEAR = 2015\n",
        "\n",
        "    # ========== v4.2 CRITICAL CHANGES ==========\n",
        "    \n",
        "    # Feature selection - MORE AGGRESSIVE\n",
        "    USE_FEATURE_SELECTION = True\n",
        "    MAX_FEATURES = 2  # Reduced from 4 to prevent overfitting!\n",
        "    \n",
        "    # Simpler feature set - NO lagged features\n",
        "    USE_LAGGED_FEATURES = False  # Disabled - adds noise\n",
        "    USE_TREND_FEATURES = True\n",
        "    \n",
        "    # Anti-overfitting\n",
        "    MAX_TRAIN_R2 = 0.5  # Reject models with Train R¬≤ > 0.5\n",
        "    \n",
        "    # REMOVED SVR - use simpler models only\n",
        "    MODELS_TO_USE = [\n",
        "        'LinearRegression',  # Baseline\n",
        "        'Ridge',\n",
        "        'Lasso', \n",
        "        'ElasticNet',\n",
        "        'BayesianRidge',\n",
        "        'KNN'\n",
        "    ]\n",
        "    \n",
        "    # STRONGER regularization\n",
        "    PARAM_GRIDS = {\n",
        "        'LinearRegression': {},  # No params\n",
        "        'Ridge': {\n",
        "            'alpha': [10.0, 50.0, 100.0, 500.0, 1000.0],  # Much higher!\n",
        "        },\n",
        "        'Lasso': {\n",
        "            'alpha': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
        "        },\n",
        "        'ElasticNet': {\n",
        "            'alpha': [0.1, 0.5, 1.0, 2.0],\n",
        "            'l1_ratio': [0.3, 0.5, 0.7],\n",
        "        },\n",
        "        'BayesianRidge': {\n",
        "            'alpha_1': [1e-5, 1e-4, 1e-3],\n",
        "            'lambda_1': [1e-5, 1e-4, 1e-3],\n",
        "        },\n",
        "        'KNN': {\n",
        "            'n_neighbors': [5, 7, 9, 11],  # More neighbors = smoother\n",
        "            'weights': ['uniform', 'distance'],\n",
        "        },\n",
        "    }\n",
        "\n",
        "    REGIONS = ['South China Sea', 'Eastern China Sea', 'Japan Sea', 'Yellow Sea']\n",
        "    OUTPUT_DIR = 'model_outputs_v42'\n",
        "\n",
        "os.makedirs(Config.OUTPUT_DIR, exist_ok=True)\n",
        "print(\"‚úÖ Configuration v4.2 complete\")\n",
        "print(f\"   Models: {Config.MODELS_TO_USE}\")\n",
        "print(f\"   Max features: {Config.MAX_FEATURES}\")\n",
        "print(f\"   Anti-overfit threshold: Train R¬≤ < {Config.MAX_TRAIN_R2}\")\n",
        "print(f\"   Lagged features: {Config.USE_LAGGED_FEATURES}\")"
      ],
      "metadata": {
        "id": "config_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ Simplified Data Loader"
      ],
      "metadata": {
        "id": "loader_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.typhoon_data = None\n",
        "        self.climate_indices = None\n",
        "\n",
        "    def load_typhoon_data(self):\n",
        "        print(\"Loading typhoon data...\")\n",
        "        self.typhoon_data = pd.read_csv(self.config.TYPHOON_DATA_PATH)\n",
        "        print(f\"  ‚úì {len(self.typhoon_data)} records\")\n",
        "        return self.typhoon_data\n",
        "\n",
        "    def load_climate_index(self, path, var_name, name):\n",
        "        try:\n",
        "            ds = xr.open_dataset(path)\n",
        "            if var_name not in ds.data_vars:\n",
        "                var_name = list(ds.data_vars)[0]\n",
        "            df = ds[var_name].to_dataframe().reset_index()\n",
        "            df['year'] = pd.to_datetime(df['time']).dt.year\n",
        "            df['month'] = pd.to_datetime(df['time']).dt.month\n",
        "            df['value'] = df[var_name]\n",
        "            ds.close()\n",
        "            return df[['year', 'month', 'value']]\n",
        "        except Exception as e:\n",
        "            print(f\"  ! {name} load failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def load_all_climate_indices(self):\n",
        "        print(\"Loading climate indices...\")\n",
        "        self.climate_indices = {}\n",
        "        for name, path, var in [\n",
        "            ('MEI', self.config.MEI_NC_PATH, self.config.MEI_VAR_NAME),\n",
        "            ('PDO', self.config.PDO_NC_PATH, self.config.PDO_VAR_NAME),\n",
        "            ('IOD', self.config.IOD_NC_PATH, self.config.IOD_VAR_NAME),\n",
        "            ('QBO', self.config.QBO_NC_PATH, self.config.QBO_VAR_NAME)\n",
        "        ]:\n",
        "            data = self.load_climate_index(path, var, name)\n",
        "            if data is not None:\n",
        "                self.climate_indices[name] = data\n",
        "                print(f\"  ‚úì {name}\")\n",
        "        return self.climate_indices\n",
        "\n",
        "    def calc_avg(self, data, year, months):\n",
        "        mask = (data['year'] == year) & (data['month'].isin(months))\n",
        "        vals = data.loc[mask, 'value']\n",
        "        return vals.mean() if len(vals) >= 2 else np.nan\n",
        "\n",
        "    def build_feature_matrix(self):\n",
        "        \"\"\"Build SIMPLIFIED feature matrix - fewer features to prevent overfitting\"\"\"\n",
        "        print(\"Building simplified feature matrix...\")\n",
        "        years = [y for y in self.typhoon_data['Year'].unique()\n",
        "                 if self.config.START_YEAR <= y <= self.config.END_YEAR]\n",
        "\n",
        "        records = []\n",
        "        for year in sorted(years):\n",
        "            rec = {'Year': year}\n",
        "            prev = year - 1\n",
        "\n",
        "            for idx, data in self.climate_indices.items():\n",
        "                # Primary feature: Oct-Nov-Dec average\n",
        "                ond = self.calc_avg(data, prev, [10, 11, 12])\n",
        "                rec[f'{idx}_OND'] = ond\n",
        "\n",
        "                # Trend feature (optional)\n",
        "                if self.config.USE_TREND_FEATURES:\n",
        "                    jas = self.calc_avg(data, prev, [7, 8, 9])\n",
        "                    rec[f'{idx}_TREND'] = ond - jas if not np.isnan(ond) and not np.isnan(jas) else np.nan\n",
        "\n",
        "            # Current year MEI for reference (not used in main prediction)\n",
        "            if 'MEI' in self.climate_indices:\n",
        "                rec['MEI_Current_JASO'] = self.calc_avg(\n",
        "                    self.climate_indices['MEI'], year, [7, 8, 9, 10]\n",
        "                )\n",
        "\n",
        "            records.append(rec)\n",
        "\n",
        "        df = pd.DataFrame(records)\n",
        "\n",
        "        # Pivot typhoon counts\n",
        "        pivot = self.typhoon_data.pivot_table(\n",
        "            index='Year', columns='Region',\n",
        "            values='Typhoon_Count', aggfunc='sum'\n",
        "        ).reset_index()\n",
        "\n",
        "        for col in pivot.columns:\n",
        "            if col != 'Year':\n",
        "                pivot = pivot.rename(columns={col: f'Target_{col}'})\n",
        "\n",
        "        result = df.merge(pivot, on='Year').dropna()\n",
        "        feature_count = len([c for c in result.columns if c not in ['Year'] and not c.startswith('Target')])\n",
        "        print(f\"  ‚úì {len(result)} samples with {feature_count} features\")\n",
        "\n",
        "        return result\n",
        "\n",
        "print(\"‚úÖ Data loader defined\")"
      ],
      "metadata": {
        "id": "loader_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6Ô∏è‚É£ Model Factory (NO SVR)"
      ],
      "metadata": {
        "id": "factory_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def create(name, params):\n",
        "        if name == 'LinearRegression':\n",
        "            return LinearRegression()\n",
        "        elif name == 'Ridge':\n",
        "            return Ridge(alpha=params.get('alpha', 100.0))\n",
        "        elif name == 'Lasso':\n",
        "            return Lasso(alpha=params.get('alpha', 1.0), max_iter=5000)\n",
        "        elif name == 'ElasticNet':\n",
        "            return ElasticNet(\n",
        "                alpha=params.get('alpha', 1.0),\n",
        "                l1_ratio=params.get('l1_ratio', 0.5),\n",
        "                max_iter=5000\n",
        "            )\n",
        "        elif name == 'BayesianRidge':\n",
        "            return BayesianRidge(\n",
        "                alpha_1=params.get('alpha_1', 1e-4),\n",
        "                lambda_1=params.get('lambda_1', 1e-4),\n",
        "            )\n",
        "        elif name == 'KNN':\n",
        "            return KNeighborsRegressor(\n",
        "                n_neighbors=params.get('n_neighbors', 7),\n",
        "                weights=params.get('weights', 'uniform')\n",
        "            )\n",
        "\n",
        "    @staticmethod\n",
        "    def get_param_combos(grid):\n",
        "        if not grid:\n",
        "            return [{}]\n",
        "        keys, vals = list(grid.keys()), list(grid.values())\n",
        "        return [dict(zip(keys, v)) for v in product(*vals)]\n",
        "\n",
        "print(\"‚úÖ Model factory defined (NO SVR)\")"
      ],
      "metadata": {
        "id": "factory_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7Ô∏è‚É£ Anti-Overfitting Model System\n",
        "\n",
        "### Key Features:\n",
        "- **Rejects models with Train R¬≤ > 0.5** (overfitting)\n",
        "- **Baseline comparison** against mean prediction\n",
        "- **Ensemble option** for combining models"
      ],
      "metadata": {
        "id": "system_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AntiOverfitModelSystem:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.results = {}\n",
        "        self.best_models = {}\n",
        "        self.trained = {}\n",
        "        self.scalers = {}\n",
        "        self.feature_selectors = {}\n",
        "        self.selected_features = {}\n",
        "        self.feature_cols = None\n",
        "        self.baseline_performance = {}\n",
        "\n",
        "    def compute_baseline(self, y_train, y_test):\n",
        "        \"\"\"Compute baseline: predicting the training mean for all test samples\"\"\"\n",
        "        mean_pred = np.full_like(y_test, y_train.mean())\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, mean_pred))\n",
        "        # R¬≤ for mean prediction is 0 by definition\n",
        "        return rmse, 0.0\n",
        "\n",
        "    def select_features_by_correlation(self, X, y, feature_names, max_features=2):\n",
        "        \"\"\"Select features by absolute correlation with target\"\"\"\n",
        "        correlations = []\n",
        "        for i, fname in enumerate(feature_names):\n",
        "            corr, _ = stats.pearsonr(X[:, i], y)\n",
        "            correlations.append((fname, i, abs(corr), corr))\n",
        "        \n",
        "        # Sort by absolute correlation\n",
        "        correlations.sort(key=lambda x: x[2], reverse=True)\n",
        "        \n",
        "        # Select top features\n",
        "        selected_idx = [c[1] for c in correlations[:max_features]]\n",
        "        selected_names = [c[0] for c in correlations[:max_features]]\n",
        "        selected_corrs = {c[0]: c[3] for c in correlations[:max_features]}\n",
        "        \n",
        "        return selected_idx, selected_names, selected_corrs, correlations\n",
        "\n",
        "    def cv_with_loo(self, X, y, model_name, params):\n",
        "        \"\"\"Leave-One-Out cross-validation\"\"\"\n",
        "        loo = LeaveOneOut()\n",
        "        predictions = []\n",
        "        actuals = []\n",
        "\n",
        "        for train_idx, test_idx in loo.split(X):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            scaler = StandardScaler()\n",
        "            X_train_s = scaler.fit_transform(X_train)\n",
        "            X_test_s = scaler.transform(X_test)\n",
        "\n",
        "            try:\n",
        "                model = ModelFactory.create(model_name, params)\n",
        "                model.fit(X_train_s, y_train)\n",
        "                pred = model.predict(X_test_s)[0]\n",
        "                predictions.append(max(0, pred))\n",
        "                actuals.append(y_test[0])\n",
        "            except:\n",
        "                return 999, 999\n",
        "\n",
        "        predictions = np.array(predictions)\n",
        "        actuals = np.array(actuals)\n",
        "        rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
        "        r2 = r2_score(actuals, predictions)\n",
        "\n",
        "        return rmse, r2\n",
        "\n",
        "    def search_best_params(self, X, y, model_name, grid):\n",
        "        \"\"\"Search for best hyperparameters with anti-overfitting constraint\"\"\"\n",
        "        combos = ModelFactory.get_param_combos(grid)\n",
        "        best_rmse = float('inf')\n",
        "        best_params = {}\n",
        "        best_cv_r2 = -999\n",
        "\n",
        "        for params in combos:\n",
        "            rmse, cv_r2 = self.cv_with_loo(X, y, model_name, params)\n",
        "\n",
        "            if rmse < best_rmse:\n",
        "                best_rmse = rmse\n",
        "                best_params = params\n",
        "                best_cv_r2 = cv_r2\n",
        "\n",
        "        return best_params, best_rmse, best_cv_r2\n",
        "\n",
        "    def train_region(self, data, region, feat_cols):\n",
        "        \"\"\"Train models with anti-overfitting measures\"\"\"\n",
        "        target = f'Target_{region}'\n",
        "        if target not in data.columns:\n",
        "            print(f\"  ! Target column {target} not found\")\n",
        "            return None\n",
        "\n",
        "        X = data[feat_cols].values\n",
        "        y = data[target].values\n",
        "        years = data['Year'].values\n",
        "\n",
        "        train_mask = years < self.config.TEST_SPLIT_YEAR\n",
        "        test_mask = years >= self.config.TEST_SPLIT_YEAR\n",
        "\n",
        "        X_train_full, X_test_full = X[train_mask], X[test_mask]\n",
        "        y_train, y_test = y[train_mask], y[test_mask]\n",
        "\n",
        "        print(f\"\\n  === {region} ===\")\n",
        "        print(f\"      Training: {len(y_train)} samples, Test: {len(y_test)} samples\")\n",
        "        print(f\"      Target - mean: {y_train.mean():.1f}, std: {y_train.std():.1f}, range: [{y_train.min():.0f}, {y_train.max():.0f}]\")\n",
        "\n",
        "        # Compute baseline (mean prediction)\n",
        "        baseline_rmse, baseline_r2 = self.compute_baseline(y_train, y_test)\n",
        "        self.baseline_performance[region] = {'rmse': baseline_rmse, 'r2': baseline_r2}\n",
        "        print(f\"      Baseline (mean): RMSE={baseline_rmse:.2f}\")\n",
        "\n",
        "        # Feature selection by correlation\n",
        "        selected_idx, selected_names, selected_corrs, all_corrs = self.select_features_by_correlation(\n",
        "            X_train_full, y_train, feat_cols, self.config.MAX_FEATURES\n",
        "        )\n",
        "        self.selected_features[region] = selected_names\n",
        "        \n",
        "        print(f\"      Feature correlations with target:\")\n",
        "        for fname, _, abs_corr, corr in all_corrs[:5]:  # Show top 5\n",
        "            marker = \"‚úì\" if fname in selected_names else \" \"\n",
        "            print(f\"        {marker} {fname}: r={corr:.3f}\")\n",
        "        \n",
        "        X_train = X_train_full[:, selected_idx]\n",
        "        X_test = X_test_full[:, selected_idx]\n",
        "\n",
        "        # Scale\n",
        "        scaler = StandardScaler()\n",
        "        X_train_s = scaler.fit_transform(X_train)\n",
        "        X_test_s = scaler.transform(X_test)\n",
        "        self.scalers[region] = scaler\n",
        "\n",
        "        # Search for best model\n",
        "        model_results = {}\n",
        "        valid_models = []\n",
        "        \n",
        "        for model_name in self.config.MODELS_TO_USE:\n",
        "            print(f\"    {model_name}...\", end=\" \")\n",
        "            grid = self.config.PARAM_GRIDS.get(model_name, {})\n",
        "\n",
        "            best_params, cv_rmse, cv_r2 = self.search_best_params(X_train, y_train, model_name, grid)\n",
        "            \n",
        "            # Train to get train R¬≤ for overfitting check\n",
        "            model = ModelFactory.create(model_name, best_params)\n",
        "            model.fit(X_train_s, y_train)\n",
        "            y_train_pred = np.maximum(model.predict(X_train_s), 0)\n",
        "            train_r2 = r2_score(y_train, y_train_pred)\n",
        "            \n",
        "            # Check for overfitting\n",
        "            is_overfit = train_r2 > self.config.MAX_TRAIN_R2\n",
        "            \n",
        "            if is_overfit:\n",
        "                print(f\"CV_RMSE={cv_rmse:.2f}, Train_R¬≤={train_r2:.2f} ‚ö†Ô∏è OVERFIT - REJECTED\")\n",
        "            else:\n",
        "                print(f\"CV_RMSE={cv_rmse:.2f}, Train_R¬≤={train_r2:.2f} ‚úì\")\n",
        "                valid_models.append(model_name)\n",
        "\n",
        "            model_results[model_name] = {\n",
        "                'params': best_params,\n",
        "                'cv_rmse': cv_rmse,\n",
        "                'cv_r2': cv_r2,\n",
        "                'train_r2': train_r2,\n",
        "                'is_overfit': is_overfit,\n",
        "                'model': model,\n",
        "                'y_train_pred': y_train_pred,\n",
        "            }\n",
        "\n",
        "        # Select best non-overfitting model\n",
        "        if valid_models:\n",
        "            best_model_name = min(valid_models, key=lambda m: model_results[m]['cv_rmse'])\n",
        "        else:\n",
        "            # If all models overfit, pick the one with lowest CV RMSE anyway\n",
        "            print(\"      ‚ö†Ô∏è All models overfit! Selecting least bad option...\")\n",
        "            best_model_name = min(model_results, key=lambda m: model_results[m]['cv_rmse'])\n",
        "        \n",
        "        best_params = model_results[best_model_name]['params']\n",
        "        final_model = model_results[best_model_name]['model']\n",
        "        y_train_pred = model_results[best_model_name]['y_train_pred']\n",
        "        \n",
        "        print(f\"  üèÜ Best model: {best_model_name}\")\n",
        "\n",
        "        # Test predictions\n",
        "        y_test_pred = np.maximum(final_model.predict(X_test_s), 0)\n",
        "\n",
        "        # Metrics\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "        test_r2 = r2_score(y_test, y_test_pred)\n",
        "        train_r2 = model_results[best_model_name]['train_r2']\n",
        "\n",
        "        # Variance analysis\n",
        "        pred_std = np.std(y_test_pred)\n",
        "        actual_std = np.std(y_test)\n",
        "        variance_ratio = pred_std / actual_std if actual_std > 0 else 0\n",
        "\n",
        "        print(f\"     Train R¬≤={train_r2:.3f}, Test R¬≤={test_r2:.3f}, Test RMSE={test_rmse:.2f}\")\n",
        "        print(f\"     Pred std={pred_std:.2f}, Actual std={actual_std:.2f}, Var.Ratio={variance_ratio:.2f}\")\n",
        "        \n",
        "        # Compare to baseline\n",
        "        improvement = (baseline_rmse - test_rmse) / baseline_rmse * 100 if baseline_rmse > 0 else 0\n",
        "        if test_rmse < baseline_rmse:\n",
        "            print(f\"     ‚úì {improvement:.1f}% better than baseline\")\n",
        "        else:\n",
        "            print(f\"     ‚ö†Ô∏è {-improvement:.1f}% worse than baseline (mean prediction)\")\n",
        "\n",
        "        # Store results\n",
        "        self.best_models[region] = best_model_name\n",
        "        self.trained[region] = final_model\n",
        "\n",
        "        self.results[region] = {\n",
        "            'models': model_results,\n",
        "            'best': best_model_name,\n",
        "            'best_params': best_params,\n",
        "            'test_rmse': test_rmse,\n",
        "            'test_r2': test_r2,\n",
        "            'train_r2': train_r2,\n",
        "            'baseline_rmse': baseline_rmse,\n",
        "            'improvement': improvement,\n",
        "            'y_train': y_train,\n",
        "            'y_train_pred': y_train_pred,\n",
        "            'y_test': y_test,\n",
        "            'y_test_pred': y_test_pred,\n",
        "            'years_train': years[train_mask],\n",
        "            'years_test': years[test_mask],\n",
        "            'pred_std': pred_std,\n",
        "            'actual_std': actual_std,\n",
        "            'variance_ratio': variance_ratio,\n",
        "            'selected_features': selected_names,\n",
        "            'feature_correlations': selected_corrs,\n",
        "        }\n",
        "\n",
        "    def train_all(self, data):\n",
        "        \"\"\"Train models for all regions\"\"\"\n",
        "        # Exclude MEI_Current_JASO from features (it's for current year)\n",
        "        self.feature_cols = [c for c in data.columns\n",
        "                           if c not in ['Year', 'MEI_Current_JASO'] and not c.startswith('Target')]\n",
        "\n",
        "        print(f\"\\nAvailable features: {len(self.feature_cols)}\")\n",
        "        print(f\"Features: {self.feature_cols}\")\n",
        "        print(f\"Max features to select: {self.config.MAX_FEATURES}\")\n",
        "\n",
        "        for region in self.config.REGIONS:\n",
        "            self.train_region(data, region, self.feature_cols)\n",
        "\n",
        "    def comparison_table(self):\n",
        "        \"\"\"Generate comparison table\"\"\"\n",
        "        rows = []\n",
        "        for region, res in self.results.items():\n",
        "            for mn, mr in res['models'].items():\n",
        "                rows.append({\n",
        "                    'Region': region,\n",
        "                    'Model': mn,\n",
        "                    'CV_RMSE': mr['cv_rmse'],\n",
        "                    'Train_R2': mr['train_r2'],\n",
        "                    'Overfit': '‚ö†Ô∏è' if mr['is_overfit'] else '‚úì',\n",
        "                    'Best': '‚òÖ' if mn == res['best'] else ''\n",
        "                })\n",
        "        return pd.DataFrame(rows)\n",
        "\n",
        "print(\"‚úÖ Anti-overfit model system defined\")"
      ],
      "metadata": {
        "id": "system_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8Ô∏è‚É£ Load Data"
      ],
      "metadata": {
        "id": "load_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "loader = DataLoader(Config)\n",
        "loader.load_typhoon_data()\n",
        "loader.load_all_climate_indices()\n",
        "data = loader.build_feature_matrix()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Data preview:\")\n",
        "display(data.head())\n",
        "\n",
        "print(f\"\\nüìä Dataset Summary:\")\n",
        "print(f\"   Total samples: {len(data)}\")\n",
        "print(f\"   Training (< {Config.TEST_SPLIT_YEAR}): {len(data[data['Year'] < Config.TEST_SPLIT_YEAR])}\")\n",
        "print(f\"   Test (>= {Config.TEST_SPLIT_YEAR}): {len(data[data['Year'] >= Config.TEST_SPLIT_YEAR])}\")"
      ],
      "metadata": {
        "id": "load_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9Ô∏è‚É£ Train Models"
      ],
      "metadata": {
        "id": "train_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"‚è≥ Training with anti-overfitting measures...\")\n",
        "print(\"   ‚Ä¢ Models with Train R¬≤ > 0.5 will be rejected\")\n",
        "print(\"   ‚Ä¢ Using only 2 best features per region\")\n",
        "print(\"   ‚Ä¢ Comparing against baseline (mean prediction)\\n\")\n",
        "\n",
        "system = AntiOverfitModelSystem(Config)\n",
        "system.train_all(data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Training complete!\")"
      ],
      "metadata": {
        "id": "train_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîü Results Analysis"
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model comparison table\n",
        "comparison = system.comparison_table()\n",
        "print(\"\\nüìä Model Comparison (with overfitting check):\")\n",
        "display(comparison)\n",
        "\n",
        "# Save\n",
        "comparison.to_csv(f'{Config.OUTPUT_DIR}/model_comparison_v42.csv', index=False)"
      ],
      "metadata": {
        "id": "results_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Visualization"
      ],
      "metadata": {
        "id": "viz_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot actual vs predicted\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (region, res) in enumerate(system.results.items()):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # Combine train and test\n",
        "    all_years = np.concatenate([res['years_train'], res['years_test']])\n",
        "    all_actual = np.concatenate([res['y_train'], res['y_test']])\n",
        "    all_pred = np.concatenate([res['y_train_pred'], res['y_test_pred']])\n",
        "\n",
        "    # Plot actual\n",
        "    ax.plot(all_years, all_actual, 'b-o', label='Actual', linewidth=2, markersize=4)\n",
        "\n",
        "    # Plot predictions\n",
        "    ax.plot(res['years_train'], res['y_train_pred'], 'g--s',\n",
        "           label='Train Pred', linewidth=1.5, markersize=3, alpha=0.7)\n",
        "    ax.plot(res['years_test'], res['y_test_pred'], 'r--^',\n",
        "           label='Test Pred', linewidth=2, markersize=5)\n",
        "\n",
        "    # Train/test split line\n",
        "    ax.axvline(x=Config.TEST_SPLIT_YEAR - 0.5, color='gray',\n",
        "              linestyle=':', linewidth=2, label='Split')\n",
        "\n",
        "    # Mean line (baseline)\n",
        "    mean_val = np.mean(res['y_train'])\n",
        "    ax.axhline(y=mean_val, color='orange', linestyle='--',\n",
        "              alpha=0.5, label=f'Baseline (mean={mean_val:.1f})')\n",
        "\n",
        "    ax.set_xlabel('Year')\n",
        "    ax.set_ylabel('Typhoon Count')\n",
        "    \n",
        "    # Title with key metrics\n",
        "    title = f'{region}\\n'\n",
        "    title += f'Best: {res[\"best\"]} | Test R¬≤={res[\"test_r2\"]:.2f} | '\n",
        "    if res['improvement'] > 0:\n",
        "        title += f'‚úì {res[\"improvement\"]:.0f}% better'\n",
        "    else:\n",
        "        title += f'‚ö†Ô∏è {-res[\"improvement\"]:.0f}% worse'\n",
        "    ax.set_title(title)\n",
        "    \n",
        "    ax.legend(loc='upper right', fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{Config.OUTPUT_DIR}/predictions_v42.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n‚úì Plot saved to {Config.OUTPUT_DIR}/predictions_v42.png\")"
      ],
      "metadata": {
        "id": "viz_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ Diagnostic Summary"
      ],
      "metadata": {
        "id": "diag_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"üìä DIAGNOSTIC SUMMARY v4.2\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "overall_better = 0\n",
        "overall_worse = 0\n",
        "\n",
        "for region, res in system.results.items():\n",
        "    print(f\"\\nüåä {region}:\")\n",
        "    print(f\"   Best Model: {res['best']}\")\n",
        "    print(f\"   Parameters: {res['best_params']}\")\n",
        "    print(f\"   Selected Features: {res['selected_features']}\")\n",
        "    print(f\"   Feature Correlations: {res['feature_correlations']}\")\n",
        "    print(f\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
        "    print(f\"   Train R¬≤: {res['train_r2']:.3f}\")\n",
        "    print(f\"   Test R¬≤: {res['test_r2']:.3f}\")\n",
        "    print(f\"   Test RMSE: {res['test_rmse']:.2f}\")\n",
        "    print(f\"   Baseline RMSE: {res['baseline_rmse']:.2f}\")\n",
        "    print(f\"   Variance Ratio: {res['variance_ratio']:.2f}\")\n",
        "    print(f\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
        "    \n",
        "    if res['improvement'] > 0:\n",
        "        print(f\"   ‚úì {res['improvement']:.1f}% BETTER than baseline\")\n",
        "        overall_better += 1\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è {-res['improvement']:.1f}% worse than baseline\")\n",
        "        overall_worse += 1\n",
        "    \n",
        "    if res['variance_ratio'] < 0.3:\n",
        "        print(f\"   ‚ö†Ô∏è Predictions still too flat\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OVERALL ASSESSMENT\")\n",
        "print(\"=\"*70)\n",
        "print(f\"   Regions better than baseline: {overall_better}/4\")\n",
        "print(f\"   Regions worse than baseline: {overall_worse}/4\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"KEY INSIGHTS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "The fundamental challenge:\n",
        "‚Ä¢ Only 37 samples (27 train, 10 test)\n",
        "‚Ä¢ Climate indices have WEAK correlations with typhoon counts\n",
        "‚Ä¢ High inter-annual variability in typhoon counts\n",
        "\n",
        "What v4.2 addressed:\n",
        "‚Ä¢ Removed SVR (was overfitting or producing flat predictions)\n",
        "‚Ä¢ Reduced features from 4 to 2 (better sample/feature ratio)\n",
        "‚Ä¢ Added anti-overfitting constraint (Train R¬≤ < 0.5)\n",
        "‚Ä¢ Strong regularization in linear models\n",
        "\n",
        "Realistic expectations:\n",
        "‚Ä¢ With 37 samples, even small improvements over baseline are meaningful\n",
        "‚Ä¢ Consider reporting predictions as ranges, not point estimates\n",
        "‚Ä¢ The \"baseline\" (predicting mean) is often hard to beat significantly\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "diag_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£3Ô∏è‚É£ Feature Importance Analysis"
      ],
      "metadata": {
        "id": "feature_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìä FEATURE ANALYSIS BY REGION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_features_used = {}\n",
        "\n",
        "for region, res in system.results.items():\n",
        "    print(f\"\\n{region}:\")\n",
        "    for feat, corr in res['feature_correlations'].items():\n",
        "        direction = \"‚Üë\" if corr > 0 else \"‚Üì\"\n",
        "        strength = \"strong\" if abs(corr) > 0.3 else \"moderate\" if abs(corr) > 0.15 else \"weak\"\n",
        "        print(f\"  ‚Ä¢ {feat}: r={corr:+.3f} {direction} ({strength})\")\n",
        "        \n",
        "        if feat not in all_features_used:\n",
        "            all_features_used[feat] = []\n",
        "        all_features_used[feat].append((region, corr))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FEATURES USED ACROSS REGIONS\")\n",
        "print(\"=\"*70)\n",
        "for feat, usages in sorted(all_features_used.items(), key=lambda x: len(x[1]), reverse=True):\n",
        "    regions = [u[0].split()[0] for u in usages]  # First word of region\n",
        "    avg_corr = np.mean([abs(u[1]) for u in usages])\n",
        "    print(f\"  {feat}: used in {len(usages)} regions, avg |r|={avg_corr:.3f}\")"
      ],
      "metadata": {
        "id": "feature_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£4Ô∏è‚É£ Alternative: Ensemble with Uncertainty"
      ],
      "metadata": {
        "id": "ensemble_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìä ENSEMBLE PREDICTION WITH UNCERTAINTY\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nCombining predictions from multiple models for better stability...\\n\")\n",
        "\n",
        "for region, res in system.results.items():\n",
        "    print(f\"\\n{region}:\")\n",
        "    \n",
        "    # Collect predictions from all non-overfitting models\n",
        "    valid_preds = []\n",
        "    for mn, mr in res['models'].items():\n",
        "        if not mr['is_overfit']:\n",
        "            # Get test predictions for this model\n",
        "            model = mr['model']\n",
        "            X_test_s = system.scalers[region].transform(\n",
        "                data[data['Year'] >= Config.TEST_SPLIT_YEAR][res['selected_features']].values\n",
        "            )\n",
        "            pred = np.maximum(model.predict(X_test_s), 0)\n",
        "            valid_preds.append(pred)\n",
        "    \n",
        "    if valid_preds:\n",
        "        # Ensemble: average of all valid models\n",
        "        ensemble_pred = np.mean(valid_preds, axis=0)\n",
        "        ensemble_std = np.std(valid_preds, axis=0)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        ensemble_rmse = np.sqrt(mean_squared_error(res['y_test'], ensemble_pred))\n",
        "        ensemble_r2 = r2_score(res['y_test'], ensemble_pred)\n",
        "        \n",
        "        print(f\"   Single best model RMSE: {res['test_rmse']:.2f}\")\n",
        "        print(f\"   Ensemble ({len(valid_preds)} models) RMSE: {ensemble_rmse:.2f}\")\n",
        "        \n",
        "        if ensemble_rmse < res['test_rmse']:\n",
        "            print(f\"   ‚úì Ensemble is better!\")\n",
        "        else:\n",
        "            print(f\"   Single model is better\")\n",
        "        \n",
        "        print(f\"\\n   Test year predictions (mean ¬± std):\")\n",
        "        test_years = res['years_test']\n",
        "        for i, (yr, actual, pred, std) in enumerate(zip(test_years, res['y_test'], ensemble_pred, ensemble_std)):\n",
        "            print(f\"     {int(yr)}: Actual={actual:.0f}, Pred={pred:.1f}¬±{std:.1f}\")"
      ],
      "metadata": {
        "id": "ensemble_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£5Ô∏è‚É£ Download Results"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(f'{Config.OUTPUT_DIR}/model_comparison_v42.csv')\n",
        "files.download(f'{Config.OUTPUT_DIR}/predictions_v42.png')\n",
        "\n",
        "print(\"‚úÖ Files downloaded!\")"
      ],
      "metadata": {
        "id": "download_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üìù Summary: v4.1 ‚Üí v4.2 Changes\n",
        "\n",
        "| Issue in v4.1 | Fix in v4.2 |\n",
        "|---------------|-------------|\n",
        "| SVR overfitting (Japan Sea Train R¬≤=1.0) | Removed SVR entirely |\n",
        "| Flat predictions (Var.Ratio ‚âà 0) | Simpler linear models with strong regularization |\n",
        "| Too many features (4) | Reduced to 2 features |\n",
        "| No baseline comparison | Added mean prediction baseline |\n",
        "| No overfitting detection | Added Train R¬≤ < 0.5 constraint |\n",
        "\n",
        "### Reality Check:\n",
        "With only **37 samples** and **weak feature-target correlations** (|r| < 0.3), \n",
        "accurate prediction is fundamentally limited. The best we can do is:\n",
        "\n",
        "1. **Avoid overfitting** (don't fool ourselves with good training metrics)\n",
        "2. **Beat the baseline** (mean prediction) even slightly\n",
        "3. **Report uncertainty** (predictions are approximate)"
      ],
      "metadata": {
        "id": "summary_cell"
      }
    }
  ]
}
